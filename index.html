<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta name="baidu-site-verification" content="L6Lm9d5Crl">
  
  
  
  
  <title>小鱼游水</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="小鱼游水">
<meta property="og:url" content="http://www.yujinyu.site/index.html">
<meta property="og:site_name" content="小鱼游水">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小鱼游水">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  
  <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
    
    
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet">
  <script>
      var yiliaConfig = {
          fancybox: true,
          animate: true,
          isHome: true,
          isPost: false,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

        <a href="/" class="profilepic">
            
            <img lazy-src="/img/avatar.jpg" class="js-avatar">
            
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Jason Jinyu Yu</a></h1>
        </hgroup>
        
        
            <form>
                <input type="text" class="st-default-search-input search" id="local-search-input" placeholder="搜索一下" autocomplete="off">
            </form>
            <div id="local-search-result"></div>
        
        
            <script type="text/javascript">
                (function() {
                    'use strict';
                    function getMatchData(keyword, data) {
                        var matchData = [];
                        for(var i =0;i<data.length;i++){
                            if(data[i].title.toLowerCase().indexOf(keyword)>=0) 
                                matchData.push(data[i])
                        }
                        return matchData;
                    }
                    var $input = $('#local-search-input');
                    var $resultContent = $('#local-search-result');
                    $input.keyup(function(){
                        $.ajax({
                            url: '/search.json',
                            dataType: "json",
                            success: function( json ) {
                                var str='<ul class=\"search-result-list\">';                
                                var keyword = $input.val().trim().toLowerCase();
                                $resultContent.innerHTML = "";
                                if ($input.val().trim().length <= 0) {
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                }
                                var results = getMatchData(keyword, json);
                                if(results.length === 0){
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                } 
                                for(var i =0; i<results.length; i++){
                                    str += "<li><a href='"+ results[i].url +"' class='search-result-title'>"+ results[i].title +"</a></li>";
                                }
                                str += "</ul>";
                                $resultContent.empty();
                                $resultContent.append(str);
                                $('#switch-area').hide();
                            }
                        });
                    });
                })();
            </script>
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        
        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/categories/阅读笔记/">阅读笔记</a></li>
                        
                            <li><a href="/categories/搞机记录/">搞机记录</a></li>
                        
                            <li><a href="/tags/">分类阅读</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail" target="_blank" href="mailto:yujinyu@hust.edu.cn" title="mail">mail</a>
                            
                                <a class="fl github" target="_blank" href="https://github.com/yujinyu" title="github">github</a>
                            
                                <a class="fl weibo" target="_blank" href="https://weibo.com/u/6933594447" title="weibo">weibo</a>
                            
                                <a class="fl rss" target="_blank" href="/atom.xml" title="rss">rss</a>
                            
                        </ul>
                    </nav>
                </section>
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/CRIU/" style="font-size: 10px;">CRIU</a> <a href="/tags/Gateway/" style="font-size: 10px;">Gateway</a> <a href="/tags/Kubernetes/" style="font-size: 10px;">Kubernetes</a> <a href="/tags/Live-Migration/" style="font-size: 10px;">Live_Migration</a> <a href="/tags/Overlay-Network/" style="font-size: 10px;">Overlay_Network</a> <a href="/tags/ShadowsocksR/" style="font-size: 10px;">ShadowsocksR</a> <a href="/tags/lock-stat/" style="font-size: 10px;">lock_stat</a> <a href="/tags/资源调度/" style="font-size: 10px;">资源调度</a>
                    </div>
                </section>
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="https://www.hust.edu.cn">华中科技大学</a>
                    
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">true</div>
                </section>
                
            </div>
        </div>
    </header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Jason Jinyu Yu</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/avatar.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Jason Jinyu Yu</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/categories/阅读笔记/">阅读笔记</a></li>
                
                    <li><a href="/categories/搞机记录/">搞机记录</a></li>
                
                    <li><a href="/tags/">分类阅读</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="mailto:yujinyu@hust.edu.cn" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/yujinyu" title="github">github</a>
                    
                        <a class="weibo" target="_blank" href="https://weibo.com/u/6933594447" title="weibo">weibo</a>
                    
                        <a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
                    
                </div>
            </nav>
        </header>
    </div>
</nav>
      <div class="body-wrap">
  
    <article id="post-test" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201903/27/test/" class="article-date">
      <time datetime="2019-03-27T11:40:33.000Z" itemprop="datePublished">2019-03-27 Wednesday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201903/27/test/">test</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-阅读笔记01-atc2017-bigc" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201903/25/阅读笔记01-atc2017-bigc/" class="article-date">
      <time datetime="2019-03-25T09:06:05.000Z" itemprop="datePublished">2019-03-25 Monday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201903/25/阅读笔记01-atc2017-bigc/">阅读笔记01-Preemptive Low Latency Datacenter Scheduling via Lightweight Virtualization</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><p>会议：<a href="https://www.usenix.org/conference/atc17/technical-sessions/presentation/chen-wei" target="_blank" rel="noopener">the 2017 USENIX Annual Technical Conference (USENIX ATC ‘17)</a><br>文章原文：<a href="https://www.usenix.org/system/files/conference/atc17/atc17-chen_wei.pdf" target="_blank" rel="noopener">paper</a><br>会议报告：<a href="https://www.usenix.org/sites/default/files/conference/protected-files/atc_slides_chen_wei_0.pdf" target="_blank" rel="noopener">ppt</a></p>
<h1 id="动机与问题"><a href="#动机与问题" class="headerlink" title="动机与问题"></a>动机与问题</h1><p>为了提高集群资源利用率，数据中心趋向于部署异构负载。但是不同负载特性和需求不同，一方面，对延迟敏感的任务需要尽可能快地被调度到目的节点；另一方面，长时间运行的任务应该在有资源空闲的时候占用集群空闲资源来提高资源利用率。问题的关键在于如何在保证短作业性能的同时，确保集群的资源利用率最大化。</p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>文章提出了一种基于容器的任务抢占方式。由于容器具有可以动态调整其运行资源的特性，通过使用容器作为任务的执行单元可以实现对任务资源的动态调整。<br>基于Hadoop YARN的架构如图所示。<br><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20190325/bigc-arch.png" alt="bigc-arch"></p>
<h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/阅读笔记/">阅读笔记</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/资源调度/">资源调度</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-使用ss或者ssr实现Linux全局FQ" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201806/15/使用ss或者ssr实现Linux全局FQ/" class="article-date">
      <time datetime="2018-06-15T09:04:05.000Z" itemprop="datePublished">2018-06-15 Friday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201806/15/使用ss或者ssr实现Linux全局FQ/">使用ss或者ssr实现Linux系统全局FQ</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="使用方法："><a href="#使用方法：" class="headerlink" title="使用方法："></a>使用方法：</h1><p>下载<a href="https://github.com/yujinyu/installSStproxyEasily.git" target="_blank" rel="noopener">https://github.com/yujinyu/installSStproxyEasily.git</a></p>
<p>1.在conf.py中选择使用代理方式是ss还是ssr，并配置账号、密码以及其他参数；</p>
<p>2.运行install_ss-redir.py安装软件并进行环境配置；</p>
<p>3.安装配置完成后，运行命令”ss-tproxy start”开始使用。</p>
<h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><p>[1]. <a href="https://www.zfl9.com/ss-redir.html" target="_blank" rel="noopener">https://www.zfl9.com/ss-redir.html</a></p>
<p>[2]. <a href="https://github.com/shadowsocksr-backup/shadowsocksr-libev" target="_blank" rel="noopener">https://github.com/shadowsocksr-backup/shadowsocksr-libev</a></p>
<p>[3]. <a href="https://github.com/shadowsocks/shadowsocks-libev.git" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-libev.git</a></p>
<p>[4]. <a href="https://github.com/zfl9/ss-tproxy.git" target="_blank" rel="noopener">https://github.com/zfl9/ss-tproxy.git</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/搞机记录/">搞机记录</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ShadowsocksR/">ShadowsocksR</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-基于Kubernetes部署kong 0.13.0" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201804/11/基于Kubernetes部署kong 0.13.0/" class="article-date">
      <time datetime="2018-04-11T09:04:25.000Z" itemprop="datePublished">2018-04-11 Wednesday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201804/11/基于Kubernetes部署kong 0.13.0/">基于Kubernetes部署kong 0.13.0</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="（一）-一些准备工作"><a href="#（一）-一些准备工作" class="headerlink" title="（一） 一些准备工作"></a>（一） 一些准备工作</h1><h4 id="1-Kubernetes部署完成并且支持DNS解析；"><a href="#1-Kubernetes部署完成并且支持DNS解析；" class="headerlink" title="1. Kubernetes部署完成并且支持DNS解析；"></a>1. Kubernetes部署完成并且支持DNS解析；</h4><h4 id="2-准备运行数据库（Postgres或者Cassandra）容器的必要的后端存储，这里我使用的heketi-glusterfs"><a href="#2-准备运行数据库（Postgres或者Cassandra）容器的必要的后端存储，这里我使用的heketi-glusterfs" class="headerlink" title="2. 准备运行数据库（Postgres或者Cassandra）容器的必要的后端存储，这里我使用的heketi-glusterfs;"></a>2. 准备运行数据库（Postgres或者Cassandra）容器的必要的后端存储，这里我使用的heketi-glusterfs;</h4><h4 id="3-特别说明，本文kong应用部署在default-namespace中"><a href="#3-特别说明，本文kong应用部署在default-namespace中" class="headerlink" title="3. 特别说明，本文kong应用部署在default namespace中"></a>3. 特别说明，本文kong应用部署在default namespace中</h4><h1 id="（二）Kong部署过程"><a href="#（二）Kong部署过程" class="headerlink" title="（二）Kong部署过程"></a>（二）Kong部署过程</h1><h2 id="1-创建StorageClass，为运行数据库Postgres或者Cassandra做准备；"><a href="#1-创建StorageClass，为运行数据库Postgres或者Cassandra做准备；" class="headerlink" title="1. 创建StorageClass，为运行数据库Postgres或者Cassandra做准备；"></a>1. 创建StorageClass，为运行数据库Postgres或者Cassandra做准备；</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># cat glusterfs-storageclass.yaml    </span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: glusterfs-sc</span><br><span class="line">  annotations:</span><br><span class="line">    storageclass.kubernetes.io/is-default-class: &quot;true&quot;</span><br><span class="line">provisioner: kubernetes.io/glusterfs</span><br><span class="line">parameters:</span><br><span class="line">  resturl: &quot;http://heketi-sever:port&quot;</span><br><span class="line">  restuser: &quot;username&quot;</span><br><span class="line">  restuserkey: &quot;password&quot;</span><br></pre></td></tr></table></figure>
<p>使用glusterfs-storageclass.yaml在Kubernetes中创建StorageClass glusterfs-sc。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f glusterfs-storageclass.yaml</span><br></pre></td></tr></table></figure></p>
<h2 id="2-运行并初始化数据库"><a href="#2-运行并初始化数据库" class="headerlink" title="2. 运行并初始化数据库"></a>2. 运行并初始化数据库</h2><p>官方给出了支持的两种数据库：Postgres和Cassandra，在此我选择了Cassandra。</p>
<h3 id="1-运行Cassandra数据库"><a href="#1-运行Cassandra数据库" class="headerlink" title="1. 运行Cassandra数据库"></a>1. 运行Cassandra数据库</h3><p>Cassandra服务以及StatefulSet的描述文件如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"># cat cassandra.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: cassandra</span><br><span class="line">  name: cassandra</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9042</span><br><span class="line">  selector:</span><br><span class="line">    app: cassandra</span><br><span class="line">---</span><br><span class="line">apiVersion: &quot;apps/v1beta1&quot;</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: cassandra</span><br><span class="line">spec:</span><br><span class="line">  serviceName: cassandra</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: cassandra</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: cassandra</span><br><span class="line">        # image: yujinyu/cassandra:v12</span><br><span class="line">        image: cassandra</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 7000</span><br><span class="line">          name: intra-node</span><br><span class="line">        - containerPort: 7001</span><br><span class="line">          name: tls-intra-node</span><br><span class="line">        - containerPort: 7199</span><br><span class="line">          name: jmx</span><br><span class="line">        - containerPort: 9042</span><br><span class="line">          name: cql</span><br><span class="line">        env:</span><br><span class="line">          - name: MAX_HEAP_SIZE</span><br><span class="line">            value: 512M</span><br><span class="line">          - name: HEAP_NEWSIZE</span><br><span class="line">            value: 100M</span><br><span class="line">          - name: CASSANDRA_SEEDS</span><br><span class="line">            # 根据部署应用所在的namespace修改以下的值</span><br><span class="line">            value: &quot;cassandra-0.cassandra.default.svc.cluster.local&quot;</span><br><span class="line">          - name: CASSANDRA_CLUSTER_NAME</span><br><span class="line">            value: &quot;K8Demo&quot;</span><br><span class="line">          - name: CASSANDRA_DC</span><br><span class="line">            value: &quot;DC1-K8Demo&quot;</span><br><span class="line">          - name: CASSANDRA_RACK</span><br><span class="line">            value: &quot;Rack1-K8Demo&quot;</span><br><span class="line">          - name: CASSANDRA_AUTO_BOOTSTRAP</span><br><span class="line">            value: &quot;false&quot;</span><br><span class="line">          - name: POD_IP</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                fieldPath: status.podIP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cassandra-data</span><br><span class="line">          mountPath: /cassandra_data</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line"> 1. metadata:</span><br><span class="line">      name: cassandra-data</span><br><span class="line">    spec:</span><br><span class="line">      accessModes: [&quot;ReadWriteOnce&quot;]</span><br><span class="line">      storageClassName: glusterfs-sc</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: 10Gi</span><br></pre></td></tr></table></figure>
<p>使用以上描述文件部署Cassandra服务以及StatefulSet，<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f cassandra.yaml</span><br></pre></td></tr></table></figure></p>
<h3 id="2-准备Cassandra数据库"><a href="#2-准备Cassandra数据库" class="headerlink" title="2. 准备Cassandra数据库"></a>2. 准备Cassandra数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># cat kong_migration_cassandra.yaml</span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-migration</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: kong-migration</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kong-migration</span><br><span class="line">        image: kong:0.13.0-centos</span><br><span class="line">        env:</span><br><span class="line">          - name: KONG_NGINX_DAEMON</span><br><span class="line">            value: &apos;off&apos;</span><br><span class="line">          - name: KONG_DATABASE</span><br><span class="line">            value: cassandra</span><br><span class="line">          - name: KONG_CASSANDRA_CONTACT_POINTS</span><br><span class="line">            value: cassandra</span><br><span class="line">          - name: KONG_CASSANDRA_KEYSPACE</span><br><span class="line">            value: kong</span><br><span class="line">        command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;kong migrations up&quot; ]</span><br><span class="line">      restartPolicy: Never</span><br></pre></td></tr></table></figure>
<p>运行kong-migration job准备并更新数据库，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f kong_migration_cassandra.yaml</span><br></pre></td></tr></table></figure>
<p>一旦job完成即在使用命令“kubectl get job kong-migration”显示内容中success下面显示为“1”，通过以下命令移除该job,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f kong_migration_cassandra.yaml</span><br></pre></td></tr></table></figure>
<h3 id="3-运行kong"><a href="#3-运行kong" class="headerlink" title="3.运行kong"></a>3.运行kong</h3><p>kong服务以及Deploy描述文件如下，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"># cat kong_cassandra.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-proxy</span><br><span class="line">spec:</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  loadBalancerSourceRanges:</span><br><span class="line">  - 0.0.0.0/0</span><br><span class="line">  ports:</span><br><span class="line">  - name: kong-proxy</span><br><span class="line">    port: 8000</span><br><span class="line">    targetPort: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: kong</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-proxy-ssl</span><br><span class="line">spec:</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  loadBalancerSourceRanges:</span><br><span class="line">  - 0.0.0.0/0</span><br><span class="line">  ports:</span><br><span class="line">  - name: kong-proxy-ssl</span><br><span class="line">    port: 8443</span><br><span class="line">    targetPort: 8443</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: kong</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-admin</span><br><span class="line">spec:</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  loadBalancerSourceRanges:</span><br><span class="line">  - 0.0.0.0/0</span><br><span class="line">  ports:</span><br><span class="line">  - name: kong-admin</span><br><span class="line">    port: 8001</span><br><span class="line">    targetPort: 8001</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: kong</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-admin-ssl</span><br><span class="line">spec:</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  loadBalancerSourceRanges:</span><br><span class="line">  - 0.0.0.0/0</span><br><span class="line">  ports:</span><br><span class="line">  - name: kong-admin-ssl</span><br><span class="line">    port: 8444</span><br><span class="line">    targetPort: 8444</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: kong</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-rc</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: kong-rc</span><br><span class="line">        app: kong</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kong</span><br><span class="line">        image: kong:0.13.0-centos</span><br><span class="line">        env:</span><br><span class="line">          - name: KONG_ADMIN_LISTEN</span><br><span class="line">            value: &quot;0.0.0.0:8001, 0.0.0.0:8444 ssl&quot;</span><br><span class="line">          - name: KONG_DATABASE</span><br><span class="line">            value: cassandra</span><br><span class="line">          - name: KONG_CASSANDRA_CONTACT_POINTS</span><br><span class="line">            value: cassandra</span><br><span class="line">          - name: KONG_CASSANDRA_KEYSPACE</span><br><span class="line">            value: kong</span><br><span class="line">          - name: KONG_CASSANDRA_REPL_FACTOR</span><br><span class="line">            value: &quot;2&quot;</span><br><span class="line">          - name: KONG_PROXY_ACCESS_LOG</span><br><span class="line">            value: &quot;/dev/stdout&quot;</span><br><span class="line">          - name: KONG_ADMIN_ACCESS_LOG</span><br><span class="line">            value: &quot;/dev/stdout&quot;</span><br><span class="line">          - name: KONG_PROXY_ERROR_LOG</span><br><span class="line">            value: &quot;/dev/stderr&quot;</span><br><span class="line">          - name: KONG_ADMIN_ERROR_LOG</span><br><span class="line">            value: &quot;/dev/stderr&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - name: admin</span><br><span class="line">          containerPort: 8001</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - name: proxy</span><br><span class="line">          containerPort: 8000</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - name: proxy-ssl</span><br><span class="line">          containerPort: 8443</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - name: admin-ssl</span><br><span class="line">          containerPort: 8444</span><br><span class="line">          protocol: TCP</span><br></pre></td></tr></table></figure></p>
<p>使用描述文件部署kong，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f kong_cassandra.yaml</span><br></pre></td></tr></table></figure>
<h3 id="4-【可选，只适用于Cassandra】保证数据库的高可靠性"><a href="#4-【可选，只适用于Cassandra】保证数据库的高可靠性" class="headerlink" title="4.【可选，只适用于Cassandra】保证数据库的高可靠性"></a>4.【可选，只适用于Cassandra】保证数据库的高可靠性</h3><p>为保证Cassandra的高可靠性扩展Cassandra StatefulSet的副本至3个，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale --replicas=3 statefulset/cassandra</span><br></pre></td></tr></table></figure>
<h1 id="（三）-验证并使用kong"><a href="#（三）-验证并使用kong" class="headerlink" title="（三） 验证并使用kong"></a>（三） 验证并使用kong</h1><h2 id="1-直接访问kong"><a href="#1-直接访问kong" class="headerlink" title="1. 直接访问kong"></a>1. 直接访问kong</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://<span class="variable">$&#123;kubernetes_master_ip&#125;</span>:$(kong_admin_nodeport&#125; | python -m json.tool</span><br></pre></td></tr></table></figure>
<p>如成功部署kong，运行以上命令不出错并有数据显示。</p>
<h2 id="2-运行Nginx实例测试"><a href="#2-运行Nginx实例测试" class="headerlink" title="2. 运行Nginx实例测试"></a>2. 运行Nginx实例测试</h2><h3 id="1-部署测试应用Nginx"><a href="#1-部署测试应用Nginx" class="headerlink" title="1. 部署测试应用Nginx"></a>1. 部署测试应用Nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: my-nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: my-nginx</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: my-nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: my-nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: my-nginx</span><br><span class="line">  labels:</span><br><span class="line">    run: my-nginx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    run: my-nginx</span><br></pre></td></tr></table></figure>
<h3 id="2-在kong中添加api"><a href="#2-在kong中添加api" class="headerlink" title="2. 在kong中添加api"></a>2. 在kong中添加api</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST --url http://<span class="variable">$&#123;kubernetes_master_ip&#125;</span>:<span class="variable">$&#123;kong_admin_nodeport&#125;</span>/apis/ --data <span class="string">'name=nginx-example-api'</span>   --data <span class="string">'hosts=nginx-example.com'</span>   --data <span class="string">'upstream_url=http://my-nginx'</span></span><br></pre></td></tr></table></figure>
<p>说明：如果部署Nginx应用和Kong不在同一namespace，则需修改命令中“<br>upstream_url”的值，加入kong在defaul而Nginx在test命名空间，那么upstream_url则应修改为“upstream_url=<a href="http://my_nginx.test.svc.cluster.local&quot;（cluster-domain默认为cluster.local）。" target="_blank" rel="noopener">http://my_nginx.test.svc.cluster.local&quot;（cluster-domain默认为cluster.local）。</a></p>
<h3 id="3-使用api访问后端Nginx服务"><a href="#3-使用api访问后端Nginx服务" class="headerlink" title="3. 使用api访问后端Nginx服务"></a>3. 使用api访问后端Nginx服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X GET  --url http://<span class="variable">$&#123;kubernetes_master_ip&#125;</span>:$(kong_proxy_nodeport&#125;/  --header <span class="string">'Host: nginx-example.com'</span></span><br></pre></td></tr></table></figure>
<p>结果如图所示，<br><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20180411/clipboard.png" alt="enter description here"></p>
<h1 id="（四）-到此已成功运行kong。"><a href="#（四）-到此已成功运行kong。" class="headerlink" title="（四） 到此已成功运行kong。"></a>（四） 到此已成功运行kong。</h1><hr>
<p>参考资料：<br>[1]. <a href="https://github.com/Kong/kong-dist-kubernetes" target="_blank" rel="noopener">https://github.com/Kong/kong-dist-kubernetes</a><br>[2]. <a href="https://getkong.org/install/kubernetes/" target="_blank" rel="noopener">https://getkong.org/install/kubernetes/</a><br>[3]. <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/storage/storage-classes/</a><br>[4]. <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/</a><br>[5]. <a href="https://github.com/IBM/Scalable-Cassandra-deployment-on-Kubernetes" target="_blank" rel="noopener">https://github.com/IBM/Scalable-Cassandra-deployment-on-Kubernetes</a><br>[6]. <a href="https://getkong.org/docs/0.13.x/getting-started/configuring-a-service/" target="_blank" rel="noopener">https://getkong.org/docs/0.13.x/getting-started/configuring-a-service/</a>     </p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/搞机记录/">搞机记录</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gateway/">Gateway</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-使用consul构建docker overlay网络" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201710/20/使用consul构建docker overlay网络/" class="article-date">
      <time datetime="2017-10-20T09:30:43.000Z" itemprop="datePublished">2017-10-20 Friday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201710/20/使用consul构建docker overlay网络/">使用consul构建跨主机的docker overlay网络</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h4 id="一、提前说明"><a href="#一、提前说明" class="headerlink" title="一、提前说明"></a>一、提前说明</h4><p>Ip: 192.168.3.xx</p>
<p>节点主机: de69,de75,de79<br>consul server主机: de82</p>
<p>配置环境之前请关闭防火墙<br>Ubuntu/Debian:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ufw disable &amp;&amp; setenforce 0</span><br></pre></td></tr></table></figure>
<p>Centos/Fedora:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld &amp;&amp; systemctl stop firewalld &amp;&amp; setenforce 0</span><br></pre></td></tr></table></figure>
<h4 id="二、配置consul服务器"><a href="#二、配置consul服务器" class="headerlink" title="二、配置consul服务器"></a>二、配置consul服务器</h4><p>在de82主机上运行 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart=always --name=consul-server\</span><br><span class="line">    -p &quot;8500:8500&quot; \</span><br><span class="line">    -h &quot;consul&quot; \</span><br><span class="line">    progrium/consul -server -bootstrap</span><br></pre></td></tr></table></figure>
<p>将其作为consul服务器主机。</p>
<h4 id="三、配置负载节点"><a href="#三、配置负载节点" class="headerlink" title="三、配置负载节点"></a>三、配置负载节点</h4><h5 id="修改de69、de75、de79节点主机上的-lib-systemd-system-docker-service，添加参数"><a href="#修改de69、de75、de79节点主机上的-lib-systemd-system-docker-service，添加参数" class="headerlink" title="修改de69、de75、de79节点主机上的/lib/systemd/system/docker.service，添加参数"></a>修改de69、de75、de79节点主机上的/lib/systemd/system/docker.service，添加参数</h5><p> -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2376  –cluster-store=consul://${serverip}:8500 –cluster-advertise ${hostip}:2376</p>
<p>Centos/Fedora系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd -H  unix://var/run/docker.sock -H tcp://0.0.0.0:2376 --cluster-store=consul://192.168.3.82:8500 --cluster-advertise 192.168.3.75:2376</span><br></pre></td></tr></table></figure>
<p>Ubuntu/Debian系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd -H fd:// -H  unix://var/run/docker.sock -H tcp://0.0.0.0:2376 --cluster-store=consul://192.168.3.82:8500 --cluster-advertise=192.168.3.69:2376</span><br></pre></td></tr></table></figure>
<h5 id="重启docker-daemon"><a href="#重启docker-daemon" class="headerlink" title="重启docker daemon"></a>重启docker daemon</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart docker</span><br></pre></td></tr></table></figure>
<h4 id="四、创建overlay网络"><a href="#四、创建overlay网络" class="headerlink" title="四、创建overlay网络"></a>四、创建overlay网络</h4><p>在其中一个节点主机上新建一个overlay网络，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create -d overlay $&#123;networkname&#125;</span><br></pre></td></tr></table></figure>
<p>这里我在de69上创建了名称为net1的网络：</p>
<p><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20171020/de69nwls.PNG" alt="de69nwls"></p>
<p>其他节点主机上运行docker network ls 也可以看到并且使用该overlay网络。<br><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20171020/de75nwls.PNG" alt="de75nwls"></p>
<h4 id="五、使用overlay网络创建跨主机通信的容器"><a href="#五、使用overlay网络创建跨主机通信的容器" class="headerlink" title="五、使用overlay网络创建跨主机通信的容器"></a>五、使用overlay网络创建跨主机通信的容器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name $&#123;container_name&#125; --network net1 busybox</span><br></pre></td></tr></table></figure>
<p>在de69创建容器bbox5，在de75 bbpx1 bbox4,在de79 bbox2 bbox3。</p>
<p>在de69中ping测试：</p>
<p><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20171020/de69ping.PNG" alt="de69ping"></p>
<p>在de75中ping测试：</p>
<p><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20171020/de75ping.PNG" alt="de75ping"></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/搞机记录/">搞机记录</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Overlay-Network/">Overlay_Network</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-lock_stat使用说明" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201709/26/lock_stat使用说明/" class="article-date">
      <time datetime="2017-09-26T03:32:43.000Z" itemprop="datePublished">2017-09-26 Tuesday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201709/26/lock_stat使用说明/">lock_stat使用记录</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h3><p>From $(path}/linux-x.x.x/Documentation/locking/lockstat.txt</p>
<h4 id="LOCK-STATISTICS"><a href="#LOCK-STATISTICS" class="headerlink" title="LOCK STATISTICS"></a>LOCK STATISTICS</h4><ul>
<li>WHAT</li>
</ul>
<p>As the name suggests, it provides statistics on locks.</p>
<ul>
<li>WHY</li>
</ul>
<p>Because things like lock contention can severely impact performance.</p>
<ul>
<li>HOW</li>
</ul>
<p>Lockdep already has hooks in the lock functions and maps lock instances to<br>lock classes. We build on that (see Documentation/locking/lockdep-design.txt).<br>The graph below shows the relation between the lock functions and the various<br>hooks therein.</p>
<pre><code> __acquire
     |
    lock _____
     |        \
     |    __contended
     |         |
     |       &lt;wait&gt;
     | _______/
     |/
     |
__acquired
     |
     .
   &lt;hold&gt;
     .
     |
__release
     |
  unlock
</code></pre><p>lock, unlock    - the regular lock functions</p>
<p>__*        - the hooks</p>
<p>&lt;&gt;         - states</p>
<p>With these hooks we provide the following statistics:</p>
<blockquote>
<p> con-bounces       - number of lock contention that involved x-cpu data<br> contentions       - number of lock acquisitions that had to wait<br> wait time min     - shortest (non-0) time we ever had to wait for a lock<br> wait time max     - longest time we ever had to wait for a lock<br> wait time total   - total time we spend waiting on this lock<br> wait time avg     - average time spent waiting on this lock<br> acq-bounces       - number of lock acquisitions that involved x-cpu data<br> acquisitions      - number of times we took the lock<br> hold time min     - shortest (non-0) time we ever held the lock<br> hold time max     - longest time we ever held the lock<br> hold time total   - total time this lock was held<br> hold time avg     - average time this lock was held         </p>
</blockquote>
<p>These numbers are gathered per lock class, per read/write state (when<br>applicable).</p>
<p>It also tracks 4 contention points per class. A contention point is a call site that had to wait on lock acquisition.</p>
<ul>
<li>CONFIGURATION</li>
</ul>
<p>Lock statistics are enabled via CONFIG_LOCK_STAT.</p>
<ul>
<li>USAGE</li>
</ul>
<p>Enable collection of statistics:</p>
<p><code># echo 1 &gt;/proc/sys/kernel/lock_stat</code>   </p>
<p>Disable collection of statistics:</p>
<p><code># echo 0 &gt;/proc/sys/kernel/lock_stat</code></p>
<p>Look at the current lock statistics:</p>
<p>( line numbers not part of actual output, done for clarity in the explanation below )</p>
<p><code># less /proc/lock_stat</code></p>
<p><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20170926/lock1.PNG" alt="less"></p>
<p>This excerpt shows the first two lock class statistics. Line 01 shows the output version - each time the format changes this will be updated. Line 02-04 show the header with column descriptions. Lines 05-18 and 20-31 show the actual statistics. These statistics come in two parts; the actual stats separated by a short separator (line 08, 13) from the contention points.<br>Lines 09-12 show the first 4 recorded contention points (the code which tries to get the lock) and lines 14-17 show the first 4 recorded contended points (the lock holder). It is possible that the max<br>con-bounces point is missing in the statistics.</p>
<p>The first lock (05-18) is a read/write lock, and shows two lines above the short separator. The contention points don’t match the column descriptors, they have two: contentions and [<ip>] symbol. The second set of contention<br>points are the points we’re contending with.</ip></p>
<p>The integer part of the time values is in us.</p>
<p>Dealing with nested locks, subclasses may appear:             </p>
<p><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20170926/lock2.PNG" alt="lock"></p>
<p>Line 48 shows statistics for the second subclass (/1) of &amp;rq-&gt;lock class (subclass starts from 0), since in this case, as line 50 suggests, double_rq_lock actually acquires a nested lock of two spinlocks.<br>View the top contending locks:<br><code># grep : /proc/lock_stat | head</code>  </p>
<p><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20170926/lock3.PNG" alt="head"></p>
<p>Clear the statistics:<br><code># echo 0 &gt; /proc/lock_stat</code>  </p>
<h3 id="对某一进程或者应用进行lock-stat"><a href="#对某一进程或者应用进行lock-stat" class="headerlink" title="对某一进程或者应用进行lock stat"></a>对某一进程或者应用进行lock stat</h3><h5 id="关闭lock-stat"><a href="#关闭lock-stat" class="headerlink" title="关闭lock_stat"></a>关闭lock_stat</h5><p><code>echo 0 &gt; /proc/sys/kernel/lock_stat</code> </p>
<h5 id="清空之前的统计数据"><a href="#清空之前的统计数据" class="headerlink" title="清空之前的统计数据"></a>清空之前的统计数据</h5><p><code>echo 0 &gt; /proc/lock_stat</code>  </p>
<h5 id="同时运行应用（或进程）和启用lock-stat"><a href="#同时运行应用（或进程）和启用lock-stat" class="headerlink" title="同时运行应用（或进程）和启用lock stat"></a>同时运行应用（或进程）和启用lock stat</h5><p><code>echo 1 &gt; /proc/sys/kernel/lock_stat</code>  </p>
<h5 id="应用（或进程）运行结束关闭lock-stat"><a href="#应用（或进程）运行结束关闭lock-stat" class="headerlink" title="应用（或进程）运行结束关闭lock stat"></a>应用（或进程）运行结束关闭lock stat</h5><p><code>echo 0 &gt; /proc/sys/kernel/lock_stat</code>  </p>
<h5 id="此时-proc-lock-stat中的数据就是应用（或进程）运行过程中的lock数据分析。"><a href="#此时-proc-lock-stat中的数据就是应用（或进程）运行过程中的lock数据分析。" class="headerlink" title="此时/proc/lock_stat中的数据就是应用（或进程）运行过程中的lock数据分析。"></a>此时/proc/lock_stat中的数据就是应用（或进程）运行过程中的lock数据分析。</h5><p>首次尝试使用lock_stat，Mark一下。  </p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/搞机记录/">搞机记录</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/lock-stat/">lock_stat</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-使用Kubernetes1.4.6源码搭建容器集群" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201611/22/使用Kubernetes1.4.6源码搭建容器集群/" class="article-date">
      <time datetime="2016-11-22T13:56:13.000Z" itemprop="datePublished">2016-11-22 Tuesday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201611/22/使用Kubernetes1.4.6源码搭建容器集群/">使用Kubernetes1.4.6源码搭建容器集群</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="一、相关准备工作"><a href="#一、相关准备工作" class="headerlink" title="一、相关准备工作"></a>一、相关准备工作</h3><h4 id="1-1、准备工作"><a href="#1-1、准备工作" class="headerlink" title="1.1、准备工作"></a>1.1、准备工作</h4><ul>
<li>准备至少两台已安装好CentOS7.2操作系统的物理机或者虚拟机（本文配置时使用的是三台KVM虚拟机）；</li>
<li>设置hostname命令：<code>hostnamectl set-hostname k8s-mst</code></li>
</ul>
<blockquote>
<table>
<thead>
<tr>
<th>角色</th>
<th>ip</th>
<th>hostname</th>
</tr>
</thead>
<tbody>
<tr>
<td>Master</td>
<td>192.168.3.87</td>
<td>k8s-mst</td>
</tr>
<tr>
<td>Node</td>
<td>192.168.3.88</td>
<td>k8s-nod1</td>
</tr>
<tr>
<td>Node</td>
<td>192.168.3.89</td>
<td>k8s-nod2</td>
</tr>
</tbody>
</table>
</blockquote>
<ul>
<li><p>为了避免和Docker的iptables产生冲突，需要关闭Node节点上的防火墙<br><code>systemctl stop firewalld</code><br><code>systemctl disable firewalld</code></p>
</li>
<li><p>为了让各个节点的时间保持一致，需要为所有节点安装NTP<br><code>yum -y install ntp</code><br><code>systemctl start ntpd</code><br><code>systemctl enable ntpd</code></p>
</li>
</ul>
<h4 id="1-2、编译Kubernetes源码-建议在Node节点上）"><a href="#1-2、编译Kubernetes源码-建议在Node节点上）" class="headerlink" title="1.2、编译Kubernetes源码(建议在Node节点上）"></a>1.2、编译Kubernetes源码(建议在Node节点上）</h4><h4 id="1-2-1、安装docker-engine"><a href="#1-2-1、安装docker-engine" class="headerlink" title="1.2.1、安装docker-engine"></a>1.2.1、安装docker-engine</h4><h4 id="官方指导资料"><a href="#官方指导资料" class="headerlink" title="官方指导资料"></a><a href="https://docs.docker.com/engine/installation/linux/centos/" target="_blank" rel="noopener">官方指导资料</a></h4><h4 id="使用以下方法可以安装较新版本"><a href="#使用以下方法可以安装较新版本" class="headerlink" title="使用以下方法可以安装较新版本"></a>使用以下方法可以安装较新版本</h4><ul>
<li>添加yum库</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo tee /etc/yum.repos.d/docker.repo &lt;&lt;-&apos;EOF&apos;</span><br><span class="line">[dockerrepo]</span><br><span class="line">name=Docker Repository</span><br><span class="line">baseurl=https://yum.dockerproject.org/repo/experimental/centos/7/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://yum.dockerproject.org/gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>安装Docker-engine<br><code>sudo yum install -y docker-engine</code></li>
</ul>
<ul>
<li>运行Docker Daemon<br><code>sudo systemctl start docker</code></li>
<li>可以使用<code>sudo systemctl status docker</code>查看docker Daemon的运行状态</li>
</ul>
<h4 id="1-2-2、安装Golang"><a href="#1-2-2、安装Golang" class="headerlink" title="1.2.2、安装Golang"></a>1.2.2、安装Golang</h4><p><code>sudo yum install -y golang</code></p>
<h4 id="1-2-3、下载Kubernetes"><a href="#1-2-3、下载Kubernetes" class="headerlink" title="1.2.3、下载Kubernetes"></a>1.2.3、下载Kubernetes</h4><ul>
<li>从Kubernetes的github下载源码<br>git clone <a href="https://github.com/kubernetes/kubernetes.git" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes.git</a></li>
<li>或者直接下载相应版本的release包<a href="https://codeload.github.com/kubernetes/kubernetes/tar.gz/v1.4.6" target="_blank" rel="noopener">https://codeload.github.com/kubernetes/kubernetes/tar.gz/v1.4.6</a></li>
<li>如果使用git clone，下载完成后进入kubernetes文件夹，使用命令<code>git checkout v1.4.6</code>，下载release包则解压<code>tar -xvf kubernetes-1.4.6.tar.gz</code>进入kubernetes文件夹；</li>
</ul>
<h4 id="1-2-4、编译Kubernetes"><a href="#1-2-4、编译Kubernetes" class="headerlink" title="1.2.4、编译Kubernetes"></a>1.2.4、编译Kubernetes</h4><ul>
<li><p>修改hosts<br>由于在Kubernetes编译过程中需要pull谷歌容器库（gcr）中的相关镜像，故需要修改hosts进行翻墙，hosts文件参考：<a href="https://github.com/racaljk/hosts" target="_blank" rel="noopener">https://github.com/racaljk/hosts</a></p>
</li>
<li><p>修改运行平台配置参数<br>根据自己的运行平台（linux/amd64)修改hack/lib/golang.sh，把KUBE_SERVER_PLATFORMS，KUBE_CLIENT_PLATFORMS和KUBE_TEST_PLATFORMS中除linux/amd64以外的其他平台注释掉，以此来减少编译所用时间</p>
</li>
</ul>
<ul>
<li><p>编译源码<br>在Kubernetes根目录下运行命令<code>make release-skip-tests</code>，编译耗时相对较长</p>
</li>
<li><p>编译成功之后，可执行文件在文件夹“_output”中</p>
</li>
</ul>
<h3 id="二、Master配置工作"><a href="#二、Master配置工作" class="headerlink" title="二、Master配置工作"></a>二、Master配置工作</h3><h4 id="2-1、安装ectd并修改配置文件"><a href="#2-1、安装ectd并修改配置文件" class="headerlink" title="2.1、安装ectd并修改配置文件"></a>2.1、安装ectd并修改配置文件</h4><h4 id="2-1-1、安装必要软件etcd"><a href="#2-1-1、安装必要软件etcd" class="headerlink" title="2.1.1、安装必要软件etcd"></a>2.1.1、安装必要软件etcd</h4><p><code>yum -y install etcd</code></p>
<h4 id="2-1-2、-修改etcd的配置文件-etc-etcd-etcd-conf"><a href="#2-1-2、-修改etcd的配置文件-etc-etcd-etcd-conf" class="headerlink" title="2.1.2、  修改etcd的配置文件/etc/etcd/etcd.conf"></a>2.1.2、  修改etcd的配置文件/etc/etcd/etcd.conf</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ETCD_NAME=default</span><br><span class="line">ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;</span><br></pre></td></tr></table></figure>
<h4 id="2-1-3、运行etcd"><a href="#2-1-3、运行etcd" class="headerlink" title="2.1.3、运行etcd"></a>2.1.3、运行etcd</h4><p><code>sudo systemctl start etcd</code></p>
<h4 id="2-1-4、配置etcd中的网络"><a href="#2-1-4、配置etcd中的网络" class="headerlink" title="2.1.4、配置etcd中的网络"></a>2.1.4、配置etcd中的网络</h4><p><code>etcdctl mk /k8s/network/config &#39;{&quot;Network&quot;:&quot;172.17.0.0/16&quot;}&#39;</code></p>
<h4 id="2-2、kubernetes环境配置"><a href="#2-2、kubernetes环境配置" class="headerlink" title="2.2、kubernetes环境配置"></a>2.2、kubernetes环境配置</h4><h4 id="2-2-1、复制命令（可执行文件）"><a href="#2-2-1、复制命令（可执行文件）" class="headerlink" title="2.2.1、复制命令（可执行文件）"></a>2.2.1、复制命令（可执行文件）</h4><p>将位于_output/release-stage/server/linux-amd64/kubernetes/server/bin/目录下的kube-apiserver、kube-controller-manager、kube-scheduler、kubectl复制到Master节点的/usr/bin/目录下</p>
<h4 id="2-2-2、创建相应的service文件以及配置文件（shell脚本）"><a href="#2-2-2、创建相应的service文件以及配置文件（shell脚本）" class="headerlink" title="2.2.2、创建相应的service文件以及配置文件（shell脚本）"></a>2.2.2、创建相应的service文件以及配置文件（shell脚本）</h4><p>根据自己的的配置修改MASTER_ADDRESS和ETCD_SERVERS<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># Copyright 2016 The Kubernetes Authors.</span><br><span class="line">#</span><br><span class="line"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line"># you may not use this file except in compliance with the License.</span><br><span class="line"># You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#     http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line"></span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;192.168.3.87&quot;&#125;</span><br><span class="line">ETCD_SERVERS=$&#123;2:-&quot;http://192.168.3.87:2379&quot;&#125;</span><br><span class="line">SERVICE_CLUSTER_IP_RANGE=$&#123;3:-&quot;10.254.0.0/16&quot;&#125;</span><br><span class="line">ADMISSION_CONTROL=$&#123;4:-&quot;NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/kubernetes/config</span><br><span class="line"># --logtostderr=true: log to standard error instead of files</span><br><span class="line">KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;</span><br><span class="line"></span><br><span class="line"># --v=0: log level for V logs</span><br><span class="line">KUBE_LOG_LEVEL=&quot;--v=0&quot;</span><br><span class="line"></span><br><span class="line"># --allow-privileged=false: If true, allow privileged containers.</span><br><span class="line">KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;</span><br><span class="line"></span><br><span class="line"># How the controller-manager, scheduler, and proxy find the apiserver</span><br><span class="line">KUBE_MASTER=&quot;--master=$&#123;MASTER_ADDRESS&#125;:8080&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/kubernetes/apiserver</span><br><span class="line"># --insecure-bind-address=127.0.0.1: The IP address on which to serve the --insecure-port.</span><br><span class="line">KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot;</span><br><span class="line"></span><br><span class="line"># --insecure-port=8080: The port on which to serve unsecured, unauthenticated access.</span><br><span class="line">KUBE_API_PORT=&quot;--insecure-port=8080&quot;</span><br><span class="line"></span><br><span class="line"># --kubelet-port=10250: Kubelet port</span><br><span class="line">NODE_PORT=&quot;--kubelet-port=10250&quot;</span><br><span class="line"></span><br><span class="line"># --etcd-servers=[]: List of etcd servers to watch (http://ip:port),</span><br><span class="line"># comma separated. Mutually exclusive with -etcd-config</span><br><span class="line">KUBE_ETCD_SERVERS=&quot;--etcd-servers=$&#123;ETCD_SERVERS&#125;&quot;</span><br><span class="line"></span><br><span class="line"># --advertise-address=&lt;nil&gt;: The IP address on which to advertise</span><br><span class="line"># the apiserver to members of the cluster.</span><br><span class="line">KUBE_ADVERTISE_ADDR=&quot;--advertise-address=$&#123;MASTER_ADDRESS&#125;&quot;</span><br><span class="line"></span><br><span class="line"># --service-cluster-ip-range=&lt;nil&gt;: A CIDR notation IP range from which to assign service cluster IPs.</span><br><span class="line"># This must not overlap with any IP ranges assigned to nodes for pods.</span><br><span class="line">KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=$&#123;SERVICE_CLUSTER_IP_RANGE&#125;&quot;</span><br><span class="line"></span><br><span class="line"># --admission-control=&quot;AlwaysAdmit&quot;: Ordered list of plug-ins</span><br><span class="line"># to do admission control of resources into cluster.</span><br><span class="line"># Comma-delimited list of:</span><br><span class="line">#   LimitRanger, AlwaysDeny, SecurityContextDeny, NamespaceExists,</span><br><span class="line">#   NamespaceLifecycle, NamespaceAutoProvision,</span><br><span class="line">#   AlwaysAdmit, ServiceAccount, ResourceQuota, DefaultStorageClass</span><br><span class="line">KUBE_ADMISSION_CONTROL=&quot;--admission-control=$&#123;ADMISSION_CONTROL&#125;&quot;</span><br><span class="line"></span><br><span class="line"># Add your own!</span><br><span class="line">KUBE_API_ARGS=&quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">KUBE_APISERVER_OPTS=&quot;   \$&#123;KUBE_LOGTOSTDERR&#125;         \\</span><br><span class="line">                        \$&#123;KUBE_LOG_LEVEL&#125;           \\</span><br><span class="line">                        \$&#123;KUBE_ETCD_SERVERS&#125;        \\</span><br><span class="line">                        \$&#123;KUBE_API_ADDRESS&#125;         \\</span><br><span class="line">                        \$&#123;KUBE_API_PORT&#125;            \\</span><br><span class="line">                        \$&#123;NODE_PORT&#125;                \\</span><br><span class="line">                        \$&#123;KUBE_ADVERTISE_ADDR&#125;      \\</span><br><span class="line">                        \$&#123;KUBE_ALLOW_PRIV&#125;          \\</span><br><span class="line">                        \$&#123;KUBE_SERVICE_ADDRESSES&#125;   \\</span><br><span class="line">                        \$&#123;KUBE_ADMISSION_CONTROL&#125;   \\</span><br><span class="line">						\$&#123;KUBE_API_ARGS&#125;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line">After=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/config</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/apiserver</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver $&#123;KUBE_APISERVER_OPTS&#125;</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/kubernetes/controller-manager</span><br><span class="line">###</span><br><span class="line"># The following values are used to configure the kubernetes controller-manager</span><br><span class="line"></span><br><span class="line"># defaults from config and apiserver should be adequate</span><br><span class="line"></span><br><span class="line"># Add your own!</span><br><span class="line">KUBE_CONTROLLER_MANAGER_ARGS=&quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=&quot;  \$&#123;KUBE_LOGTOSTDERR&#125; \\</span><br><span class="line">                                \$&#123;KUBE_LOG_LEVEL&#125;   \\</span><br><span class="line">                                \$&#123;KUBE_MASTER&#125;      \\</span><br><span class="line">                                \$&#123;KUBE_CONTROLLER_MANAGER_ARGS&#125;&quot;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/config</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/controller-manager</span><br><span class="line">ExecStart=/usr/bin/kube-controller-manager $&#123;KUBE_CONTROLLER_MANAGER_OPTS&#125;</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/kubernetes/scheduler</span><br><span class="line">###</span><br><span class="line"># kubernetes scheduler config</span><br><span class="line"></span><br><span class="line"># Add your own!</span><br><span class="line">KUBE_SCHEDULER_ARGS=&quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">KUBE_SCHEDULER_OPTS=&quot;   \$&#123;KUBE_LOGTOSTDERR&#125;     \\</span><br><span class="line">                        \$&#123;KUBE_LOG_LEVEL&#125;       \\</span><br><span class="line">                        \$&#123;KUBE_MASTER&#125;          \\</span><br><span class="line">                        \$&#123;KUBE_SCHEDULER_ARGS&#125;&quot;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/config</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/scheduler</span><br><span class="line">ExecStart=/usr/bin/kube-scheduler $&#123;KUBE_SCHEDULER_OPTS&#125;</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure></p>
<h4 id="2-2-3、运行相应的Kubernetes命令（shell-脚本）"><a href="#2-2-3、运行相应的Kubernetes命令（shell-脚本）" class="headerlink" title="2.2.3、运行相应的Kubernetes命令（shell 脚本）"></a>2.2.3、运行相应的Kubernetes命令（shell 脚本）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for svc in etcd kube-apiserver kube-controller-manager kube-scheduler; do</span><br><span class="line">	systemctl restart $svc</span><br><span class="line">	systemctl enable $svc</span><br><span class="line">	systemctl status $svc</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="三、Node配置工作"><a href="#三、Node配置工作" class="headerlink" title="三、Node配置工作"></a>三、Node配置工作</h3><h4 id="3-1、安装flannel并修改配置文件"><a href="#3-1、安装flannel并修改配置文件" class="headerlink" title="3.1、安装flannel并修改配置文件"></a>3.1、安装flannel并修改配置文件</h4><h4 id="3-1-1、安装必要软件flannel"><a href="#3-1-1、安装必要软件flannel" class="headerlink" title="3.1.1、安装必要软件flannel"></a>3.1.1、安装必要软件flannel</h4><p><code>yum -y install flannel</code></p>
<h4 id="3-1-2、-修改flannel的配置文件-etc-sysconfig-flanneld"><a href="#3-1-2、-修改flannel的配置文件-etc-sysconfig-flanneld" class="headerlink" title="3.1.2、  修改flannel的配置文件/etc/sysconfig/flanneld"></a>3.1.2、  修改flannel的配置文件/etc/sysconfig/flanneld</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FLANNEL_ETCD=&quot;http://192.168.3.87:2379&quot;</span><br><span class="line">FLANNEL_ETCD_KEY=&quot;/k8s/network&quot;</span><br></pre></td></tr></table></figure>
<h4 id="3-1-3、运行flannel"><a href="#3-1-3、运行flannel" class="headerlink" title="3.1.3、运行flannel"></a>3.1.3、运行flannel</h4><p><code>systemctl restart flanneld</code><br><code>systemctl enable flanneld</code><br><code>systemctl status flanneld</code></p>
<h4 id="3-1-4、上传网络配置"><a href="#3-1-4、上传网络配置" class="headerlink" title="3.1.4、上传网络配置"></a>3.1.4、上传网络配置</h4><p>创建一个config.json文件，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;Network&quot;: &quot;172.17.0.0/16&quot;,</span><br><span class="line">&quot;SubnetLen&quot;: 24,</span><br><span class="line">&quot;Backend&quot;: &#123;</span><br><span class="line">     &quot;Type&quot;: &quot;vxlan&quot;,</span><br><span class="line">     &quot;VNI&quot;: 7890</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>然后将配置上传到etcd服务器上：<br><code>curl -L http://192.168.3.87:2379/v2/keys/k8s/network/config -XPUT --data-urlencode value@config.json</code></p>
<h4 id="3-2、kubernetes环境配置"><a href="#3-2、kubernetes环境配置" class="headerlink" title="3.2、kubernetes环境配置"></a>3.2、kubernetes环境配置</h4><h4 id="3-2-1、复制命令（可执行文件）"><a href="#3-2-1、复制命令（可执行文件）" class="headerlink" title="3.2.1、复制命令（可执行文件）"></a>3.2.1、复制命令（可执行文件）</h4><p>将位于_output/release-stage/server/linux-amd64/kubernetes/server/bin/目录下的kube-proxy、kubelet 复制到Node节点的/usr/bin/目录下</p>
<h4 id="3-2-2、创建相应的service文件以及配置文件（shell脚本）"><a href="#3-2-2、创建相应的service文件以及配置文件（shell脚本）" class="headerlink" title="3.2.2、创建相应的service文件以及配置文件（shell脚本）"></a>3.2.2、创建相应的service文件以及配置文件（shell脚本）</h4><p>根据自己的的配置修改MASTER_ADDRESS和NODE_HOSTNAME<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># Copyright 2016 The Kubernetes Authors.</span><br><span class="line">#</span><br><span class="line"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line"># you may not use this file except in compliance with the License.</span><br><span class="line"># You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#     http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line"></span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;192.168.3.87&quot;&#125;</span><br><span class="line">NODE_HOSTNAME=$&#123;2:-&quot;k8s-nod&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/kubernetes/config</span><br><span class="line"># --logtostderr=true: log to standard error instead of files</span><br><span class="line">KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;</span><br><span class="line"></span><br><span class="line"># --v=0: log level for V logs</span><br><span class="line">KUBE_LOG_LEVEL=&quot;--v=0&quot;</span><br><span class="line"></span><br><span class="line"># --allow-privileged=false: If true, allow privileged containers.</span><br><span class="line">KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;</span><br><span class="line"></span><br><span class="line"># How the controller-manager, scheduler, and proxy find the apiserver</span><br><span class="line">KUBE_MASTER=&quot;--master=$&#123;MASTER_ADDRESS&#125;:8080&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/kubernetes/proxy</span><br><span class="line">###</span><br><span class="line"># kubernetes proxy config</span><br><span class="line"></span><br><span class="line"># default config should be adequate</span><br><span class="line"></span><br><span class="line"># Add your own!</span><br><span class="line">KUBE_PROXY_ARGS=&quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">KUBE_PROXY_OPTS=&quot;   \$&#123;KUBE_LOGTOSTDERR&#125; \\</span><br><span class="line">                    \$&#123;KUBE_LOG_LEVEL&#125;   \\</span><br><span class="line">                    \$&#123;KUBE_MASTER&#125;    \\</span><br><span class="line">                    \$&#123;KUBE_PROXY_ARGS&#125;&quot;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-proxy.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/config</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-proxy</span><br><span class="line">ExecStart=/usr/bin/kube-proxy $&#123;KUBE_PROXY_OPTS&#125;</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/kubernetes/kubelet</span><br><span class="line"># --address=0.0.0.0: The IP address for the Kubelet to serve on (set to 0.0.0.0 for all interfaces)</span><br><span class="line">KUBELET__ADDRESS=&quot;--address=0.0.0.0&quot;</span><br><span class="line"></span><br><span class="line"># --port=10250: The port for the Kubelet to serve on. Note that &quot;kubectl logs&quot; will not work if you set this flag.</span><br><span class="line">KUBELET_PORT=&quot;--port=10250&quot;</span><br><span class="line"></span><br><span class="line"># --hostname-override=&quot;&quot;: If non-empty, will use this string as identification instead of the actual hostname.</span><br><span class="line">KUBELET_HOSTNAME=&quot;--hostname-override=$&#123;NODE_HOSTNAME&#125;&quot;</span><br><span class="line"></span><br><span class="line"># --api-servers=[]: List of Kubernetes API servers for publishing events,</span><br><span class="line"># and reading pods and services. (ip:port), comma separated.</span><br><span class="line">KUBELET_API_SERVER=&quot;--api-servers=$&#123;MASTER_ADDRESS&#125;:8080&quot;</span><br><span class="line"></span><br><span class="line"># pod infrastructure container</span><br><span class="line">KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;</span><br><span class="line"></span><br><span class="line"># Add your own!</span><br><span class="line">KUBELET_ARGS=&quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">KUBE_PROXY_OPTS=&quot;   \$&#123;KUBE_LOGTOSTDERR&#125;     \\</span><br><span class="line">                    \$&#123;KUBE_LOG_LEVEL&#125;       \\</span><br><span class="line">                    \$&#123;KUBELET__ADDRESS&#125;         \\</span><br><span class="line">                    \$&#123;KUBELET_PORT&#125;            \\</span><br><span class="line">                    \$&#123;KUBELET_HOSTNAME&#125;        \\</span><br><span class="line">                    \$&#123;KUBELET_API_SERVER&#125;   \\</span><br><span class="line">                    \$&#123;KUBE_ALLOW_PRIV&#125;      \\</span><br><span class="line">					\$&#123;KUBELET_POD_INFRA_CONTAINER&#125;\\</span><br><span class="line">                    \$&#123;KUBELET_ARGS&#125;&quot;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/config</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kubelet</span><br><span class="line">ExecStart=/usr/bin/kubelet $&#123;KUBE_PROXY_OPTS&#125;</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure></p>
<h4 id="3-2-3、运行相应的Kubernetes命令（shell脚本）"><a href="#3-2-3、运行相应的Kubernetes命令（shell脚本）" class="headerlink" title="3.2.3、运行相应的Kubernetes命令（shell脚本）"></a>3.2.3、运行相应的Kubernetes命令（shell脚本）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for svc in kube-proxy kubelet docker; do</span><br><span class="line">	systemctl restart $svc</span><br><span class="line">	systemctl enable $svc</span><br><span class="line">	systemctl status $svc</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="四、验证配置以及创建dashboard"><a href="#四、验证配置以及创建dashboard" class="headerlink" title="四、验证配置以及创建dashboard"></a>四、验证配置以及创建dashboard</h3><h4 id="4-1、验证环境配置"><a href="#4-1、验证环境配置" class="headerlink" title="4.1、验证环境配置"></a>4.1、验证环境配置</h4><p>在Master节点运行命令<code>kubectl get nodes</code>，输出信息如下：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-mst ~]# kubectl get nodes</span><br><span class="line"> NAME      STATUS    AGE</span><br><span class="line"> nod1       Ready     3h</span><br><span class="line"> nod2       Ready     3h</span><br></pre></td></tr></table></figure>
<h4 id="4-2、搭建dashboard"><a href="#4-2、搭建dashboard" class="headerlink" title="4.2、搭建dashboard"></a>4.2、搭建dashboard</h4><h4 id="4-2-1、创建命名空间（namespace）kube-system"><a href="#4-2-1、创建命名空间（namespace）kube-system" class="headerlink" title="4.2.1、创建命名空间（namespace）kube-system"></a>4.2.1、创建命名空间（namespace）kube-system</h4><p>创建文件kubernetes-namespace.jason，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;Namespace&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;kube-system&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用命令<code>kubectl create -f kubernetes-namespace.jason</code>创建kube-system命名空间。</p>
<h4 id="4-2-2、创建dashboard"><a href="#4-2-2、创建dashboard" class="headerlink" title="4.2.2、创建dashboard"></a>4.2.2、创建dashboard</h4><p>创建kubernetes-dashboard.yaml文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># Configuration to deploy release version of the Dashboard UI.</span><br><span class="line"># Example usage: kubectl create -f &lt;this_file&gt;</span><br><span class="line"></span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: kubernetes-dashboard</span><br><span class="line">      # Comment the following annotaion if Dashboard must not be deployed on master</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/tolerations: |</span><br><span class="line">          [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;key&quot;: &quot;dedicated&quot;,</span><br><span class="line">              &quot;operator&quot;: &quot;Equal&quot;,</span><br><span class="line">              &quot;value&quot;: &quot;master&quot;,</span><br><span class="line">              &quot;effect&quot;: &quot;NoSchedule&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ]</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kubernetes-dashboard</span><br><span class="line">        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.2</span><br><span class="line">        imagePullPolicy: Always</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9090</span><br><span class="line">          protocol: TCP</span><br><span class="line">        args:</span><br><span class="line">          # Uncomment the following line to manually specify Kubernetes API server Host</span><br><span class="line">          # If not specified, Dashboard will attempt to auto discover the API server and connect</span><br><span class="line">          # to it. Uncomment only if the default does not work.</span><br><span class="line">          - --apiserver-host=http://192.168.3.87:8080</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /</span><br><span class="line">            port: 9090</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 30</span><br><span class="line">---</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 9090</span><br><span class="line">  selector:</span><br><span class="line">    app: kubernetes-dashboard</span><br></pre></td></tr></table></figure></p>
<p>注意：</p>
<blockquote>
<ol>
<li>修改 –apiserver-host=http://<strong><em>192.168.3.87</em></strong>:8080；</li>
<li>其中 “ image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.2 ”，使用的是谷歌镜像库，需要Node节点翻墙才会可能正常创建。</li>
</ol>
</blockquote>
<ul>
<li><p>使用命令<code>kubectl create -f kubernetes-dashboard.yaml</code>创建kubernetes-dashboard Deployment和Service。</p>
</li>
<li><p>如无法获取相应的镜像创建之后，使用命令<code>kubectl get pod  --namespace=&quot;kube-system&quot;</code>查看会显示如下结果：</p>
</li>
</ul>
<figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@mst ~]# kubectl get pod --<span class="keyword">namespace</span>=<span class="string">"kube-system"</span></span><br><span class="line">NAME                                  READY     STATUS         RESTARTS   AGE</span><br><span class="line">kubernetes-dashboard<span class="number">-47291540</span>-lcuox   <span class="number">0</span>/<span class="number">1</span>       ErrImagePull   <span class="number">0</span>          <span class="number">1</span>m</span><br></pre></td></tr></table></figure>
<ul>
<li>搭建自己的镜像库，可参考【Docker实战】Registry &amp; Portus搭建详解 - 龍隐 - 博客园  <a href="http://www.cnblogs.com/xcloudbiz/articles/5497037.html" target="_blank" rel="noopener">http://www.cnblogs.com/xcloudbiz/articles/5497037.html</a></li>
</ul>
<h4 id="4-2-3、使用dashboard"><a href="#4-2-3、使用dashboard" class="headerlink" title="4.2.3、使用dashboard"></a>4.2.3、使用dashboard</h4><p>成功运行之后：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-mst ~]# kubectl get pod --namespace=&quot;kube-system&quot;</span><br><span class="line">NAME                                    READY     STATUS    RESTARTS   AGE</span><br><span class="line">kubernetes-dashboard-3856900779-226mr   1/1       Running   0          2m</span><br><span class="line"></span><br><span class="line">[root@k8s-mst ~]# kubectl describe  pod kubernetes-dashboard-3856900779-226mr --namespace=&quot;kube-system&quot;</span><br><span class="line">Name:		kubernetes-dashboard-3856900779-226mr</span><br><span class="line">Namespace:	kube-system</span><br><span class="line">Node:		nod1/192.168.3.91</span><br><span class="line">Start Time:	Tue, 22 Nov 2016 20:33:04 +0800</span><br><span class="line">Labels:		app=kubernetes-dashboard</span><br><span class="line">		pod-template-hash=3856900779</span><br><span class="line">Status:		Running</span><br><span class="line">IP:		172.18.0.2</span><br><span class="line">Controllers:	ReplicaSet/kubernetes-dashboard-3856900779</span><br><span class="line">Containers:</span><br><span class="line">  kubernetes-dashboard:</span><br><span class="line">    Container ID:	docker://d36cff522129c73f0de370857124697659662c99d370af548a1367604bac7014</span><br><span class="line">    Image:		gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.2</span><br><span class="line">    Image ID:		docker://sha256:c0e4ba8968ee756368cbe5f64f39b0ef8e128de90d0bdfe1d040f0773055e68a</span><br><span class="line">    Port:		9090/TCP</span><br><span class="line">    Args:</span><br><span class="line">      --apiserver-host=http://192.168.3.87:8080</span><br><span class="line">    State:			Running</span><br><span class="line">      Started:			Tue, 22 Nov 2016 20:35:00 +0800</span><br><span class="line">    Ready:			True</span><br><span class="line">    Restart Count:		0</span><br><span class="line">    Liveness:			http-get http://:9090/ delay=30s timeout=30s period=10s #success=1 #failure=3</span><br><span class="line">    Volume Mounts:		&lt;none&gt;</span><br><span class="line">    Environment Variables:	&lt;none&gt;</span><br><span class="line">Conditions:</span><br><span class="line">  Type		Status</span><br><span class="line">  Initialized 	True</span><br><span class="line">  Ready 	True</span><br><span class="line">  PodScheduled 	True</span><br><span class="line">No volumes.</span><br><span class="line">QoS Class:	BestEffort</span><br><span class="line">Tolerations:	dedicated=master:Equal:NoSchedule</span><br><span class="line">Events:</span><br><span class="line">  FirstSeen	LastSeen	Count	From			SubobjectPath				Type		Reason			Message</span><br><span class="line">  ---------	--------	-----	----			-------------				--------	------			-------</span><br><span class="line">  4m		4m		1	&#123;default-scheduler &#125;						Normal		Scheduled		Successfully assigned kubernetes-dashboard-3856900779-226mr to nod1</span><br><span class="line">  3m		3m		1	&#123;kubelet nod1&#125;		spec.containers&#123;kubernetes-dashboard&#125;	Normal		Pulling			pulling image &quot;gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.2&quot;</span><br><span class="line">  3m		2m		2	&#123;kubelet nod1&#125;							Warning		MissingClusterDNS	kubelet does not have ClusterDNS IP configured and cannot create Pod using &quot;ClusterFirst&quot; policy. Falling back to DNSDefault policy.</span><br><span class="line">  2m		2m		1	&#123;kubelet nod1&#125;		spec.containers&#123;kubernetes-dashboard&#125;	Normal		Pulled			Successfully pulled image &quot;gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.2&quot;</span><br><span class="line">  2m		2m		1	&#123;kubelet nod1&#125;		spec.containers&#123;kubernetes-dashboard&#125;	Normal		Created			Created container with docker id d36cff522129; Security:[seccomp=unconfined]</span><br><span class="line">  2m		2m		1	&#123;kubelet nod1&#125;		spec.containers&#123;kubernetes-dashboard&#125;	Normal		Started			Started container with docker id d36cff522129</span><br><span class="line"></span><br><span class="line">[root@mst ~]# kubectl describe service  kubernetes-dashboard  --namespace=&quot;kube-system&quot;</span><br><span class="line">Name:			kubernetes-dashboard</span><br><span class="line">Namespace:		kube-system</span><br><span class="line">Labels:			app=kubernetes-dashboard</span><br><span class="line">Selector:		app=kubernetes-dashboard</span><br><span class="line">Type:			NodePort</span><br><span class="line">IP:			10.254.196.154</span><br><span class="line">External IPs:		192.168.3.87</span><br><span class="line">Port:			&lt;unset&gt;	80/TCP</span><br><span class="line">NodePort:		&lt;unset&gt;	31437/TCP</span><br><span class="line">Endpoints:		172.18.0.2:9090</span><br><span class="line">Session Affinity:	None</span><br></pre></td></tr></table></figure>
<p>运行成功之后，就可以使用浏览器访问192.168.3.89:31437使用dashboard。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/搞机记录/">搞机记录</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-CRIU的安装与使用" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201611/08/CRIU的安装与使用/" class="article-date">
      <time datetime="2016-11-08T10:34:51.000Z" itemprop="datePublished">2016-11-08 Tuesday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201611/08/CRIU的安装与使用/">CRIU的安装与使用</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="CRIU安装："><a href="#CRIU安装：" class="headerlink" title="CRIU安装："></a>CRIU安装：</h3><h5 id="获取CRIU的源代码"><a href="#获取CRIU的源代码" class="headerlink" title="获取CRIU的源代码"></a>获取CRIU的源代码</h5><p>git clone<a href="https://github.com/xemul/criu" target="_blank" rel="noopener">https://github.com/xemul/criu</a><br>或者<br>wget <a href="http://download.openvz.org/criu/criu-x.x.tar.bz2" target="_blank" rel="noopener">http://download.openvz.org/criu/criu-x.x.tar.bz2</a><br>tar -xvf criu-x.x.tar.bz2</p>
<h5 id="安装编译依赖软件"><a href="#安装编译依赖软件" class="headerlink" title="安装编译依赖软件"></a>安装编译依赖软件</h5><p>yum install gcc make -y<br>yum install glibc-devel.i686 protobuf protobuf-c protobuf-c-devel protobuf-compiler protobuf-devel protobuf-python libaio-devel libcap-devel libnl3-devel -y<br>在CRIU代码根目录下，执行编译命令 make</p>
<h5 id="安装依赖软件"><a href="#安装依赖软件" class="headerlink" title="安装依赖软件"></a>安装依赖软件</h5><p>yum install asciidoc xmlto -y<br>在CRIU代码根目录下，运行安装命令 make install</p>
<h3 id="CRIU使用："><a href="#CRIU使用：" class="headerlink" title="CRIU使用："></a>CRIU使用：</h3><p>命令格式：criu dump -D chkpoint -t pid<br>CRIU环境检查, 创建一个无限循环脚本文件。</p>
<p><img src="https://github.com/yujinyu/MyDocuments/tree/master/BlogFiles/20161108/20161108163852230.png" alt></p>
<p>并运行脚本文件。</p>
<p>[root@de69 ~]# chmod +x test.sh</p>
<p>[root@de69 ~]# ./test.sh</p>
<p>创建一个新的终端，获得test.sh的pid，“pgrep -f test.sh”</p>
<p>[root@de69 ~]# criu dump -t $PID –images-dir chkpoint –shell-job</p>
<p><img src="https://github.com/yujinyu/MyDocuments/tree/master/BlogFiles/20161108/20161108163926605.png" alt></p>
<p>[root@de69 ~]# criu restore -t 23267 –images-dir chkpoint/ –shell-job<br> 运行命令之后test.sh恢复正常运行。</p>
<h4 id="在使用CRIU对Docker容器进行操作时出现以下提示错误"><a href="#在使用CRIU对Docker容器进行操作时出现以下提示错误" class="headerlink" title="在使用CRIU对Docker容器进行操作时出现以下提示错误"></a>在使用CRIU对Docker容器进行操作时出现以下提示错误</h4><blockquote>
<p>Error (criu/namespaces.c:403): Can’t dump nested pid namespace for 23025</p>
<p>Error (criu/namespaces.c:607): Can’t make pidns id</p>
<p>Error (criu/cr-dump.c:1625): Dumping FAILED.</p>
</blockquote>
<p><img src="https://github.com/yujinyu/MyDocuments/tree/master/BlogFiles/20161108/20161108163956808.png" alt></p>
<p>参看pid=23025的应用</p>
<p><img src="https://github.com/yujinyu/MyDocuments/tree/master/BlogFiles/20161108/20161108164007875.png" alt></p>
<p>[root@de69 ~]# criu dump -t 23025 –images-dir /tmp/doc01/<br><img src="https://github.com/yujinyu/MyDocuments/blob/master/BlogFiles/20161108/20161108164012230.png" alt></p>
<p>原因是当前CRIU并不完善（如不支持seccomp、不支持外部终端、挂载的文件系统可读等），Docker容器对宿主机的应用（例如“/bin/bash”等）有依赖，而CRIU不能对非Docker容器进程树中的进程设置检查点，从而导致Checkpoint/Restore失败。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/搞机记录/">搞机记录</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CRIU/">CRIU</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-KVM虚拟机在线迁移环境配置" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/201606/11/KVM虚拟机在线迁移环境配置/" class="article-date">
      <time datetime="2016-06-11T08:18:36.000Z" itemprop="datePublished">2016-06-11 Saturday</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/201606/11/KVM虚拟机在线迁移环境配置/">KVM虚拟机在线迁移环境配置</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="简要配置步骤："><a href="#简要配置步骤：" class="headerlink" title="简要配置步骤："></a>简要配置步骤：</h2><ol>
<li>在两台服务器上安装CentOS7的系统。</li>
<li>编译使用4.3.0版本内核，注意配置KVM以及虚拟设备驱动等模块。</li>
<li><p>实现两台主机无密码ssh登录，</p>
<blockquote>
<p>1)运行：ssh-keygen -t rsa ;<br>2)然后拍两下回车（均选择默认） ;<br>3)运行：ssh-copy-id -i /root/.ssh/id_rsa.pub root@target_host;<br>4)再输入163机器上的root密码。</p>
</blockquote>
</li>
<li><p>关闭源与目标主机的防火墙（否则出现错误“Unable to migrate guest: unable to connect to<br>server at ‘target_addr:49152’: No route to host”）。</p>
</li>
<li>确保两台主机libvirtd都在运行。</li>
<li>源主机端打开virt-manager，Add Connection，添加对目标主机的链接。</li>
<li>在源主机创建虚拟机，并在目标主机相同的路径创建大于等于源虚拟机大小，相同格式相同名称的镜像文件（否则出现error：Unable to<br>migrate guest: Cannot access storage file ‘/home/images/vm01.qcow2’<br>(as uid:107, gid:107): No such file or directory）。</li>
<li>可以使用virt-manage进行libvirtd、tcp在线迁移，如命令：virsh migrate –live –copy-storage-all vmname qemu+ssh(or tcp)://dest_ip/system</li>
</ol>
<h2 id="可能出现的错误或者问题及其解决方法："><a href="#可能出现的错误或者问题及其解决方法：" class="headerlink" title="可能出现的错误或者问题及其解决方法："></a>可能出现的错误或者问题及其解决方法：</h2><p>执行迁移命令的时候<br>1、出现错误：“error: internal error: unable to execute QEMU command ‘migrate’: this feature or command is not currently supported”。</p>
<p>通过查询(Re: [libvirt-users] Libvirt Live Migration  <a href="https://www.redhat.com/archives/libvirt-users/2014-December/msg00008.html)说是qemu-kvm版本的问题，使用的是qemu-kvm-1.5.3。网上提出问题的人说他使用qemu-kvm-1.0的可以。解决方法：推荐使用qemu-kvm-rhev" target="_blank" rel="noopener">https://www.redhat.com/archives/libvirt-users/2014-December/msg00008.html)说是qemu-kvm版本的问题，使用的是qemu-kvm-1.5.3。网上提出问题的人说他使用qemu-kvm-1.0的可以。解决方法：推荐使用qemu-kvm-rhev</a> 代替 qemu-kvm。</p>
<p>2、 出现错误：“Unable to migrate guest: internal error: process exited while connecting to monitor: Could not access KVM kernel module: Permission denied failed to initialize KVM: Permission denied“</p>
<p>解决方法：修改/etc/libvirt/qemu.conf，使user=root，group=root，dynamic_ownership = 0然后重启服务libvirtd。</p>
<p>3、出现错误：“Could not access KVM kernel module: Permission denied failed to initialize KVM :  Permission denied</p>
<p>解决方法：rmmod kvm_intel; rmmod kvm; modprobe kvm; modprobe kvm_intel</p>
<p>4、出现错误：“Error starting domain: internal error: process exited while connecting to monitor: qemu-system-x86_64:  …… Can’t use ‘raw’ as a block driver for the protocol level”</p>
<p>解决方法： 删除CD-ROM模块。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/搞机记录/">搞机记录</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Live-Migration/">Live_Migration</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
  

</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2019 Jason Jinyu Yu
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo &nbsp;&nbsp;</a><a href="https://github.com/maochunguang" target="_blank">Blog</a> by tommy
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style="display:none">
                        <span id="site-visit">极客到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style="display:none">
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

<script src="/js/main.js"></script>

    <script>
        $(document).ready(function() {
            var backgroundnum = 2;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>


<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-137025053-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?xxxxxx";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(
            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


  </div>
</body>
</html>